## ğŸ§© Insurance Cost Analysis (Python, Scikit-learn)

### ğŸ¯ **Project Objective**

Predict individual **medical insurance charges** using demographic and lifestyle data such as **age**, **BMI**, **smoking status**, and **region**.
This project demonstrates how polynomial regression can capture non-linear relationships and significantly improve prediction accuracy.

---

### ğŸ“‚ **Dataset**

**Source:**
[Medical Insurance Dataset](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/medical_insurance_dataset.csv)

**File Path Used in Project:**

```python
filepath = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/medical_insurance_dataset.csv'
```

**Columns:**
`age`, `sex`, `bmi`, `children`, `smoker`, `region`, `charges`

**Target Variable:**
`charges` â€“ represents the medical insurance cost.

---

### âš™ï¸ **Tools & Libraries Used**

* Python ğŸ
* Pandas, NumPy â€“ data cleaning and manipulation
* Matplotlib, Seaborn â€“ visualization
* Scikit-learn â€“ modeling and pipeline creation

---

### ğŸ§¹ **Data Preparation**

â€¢ Handled missing values and verified data types
â€¢ Encoded categorical features (`sex`, `smoker`, `region`) using `pd.get_dummies()`
â€¢ Split dataset into **training** and **testing** subsets
â€¢ Scaled numeric features using `StandardScaler()`

---

### ğŸ§  **Modeling Steps**

â€¢ Built a **Linear Regression** baseline model
â€¢ Created a **Pipeline** including:

* `StandardScaler()` â€“ normalizes data
* `PolynomialFeatures(degree=2)` â€“ adds squared and interaction terms
* `LinearRegression()` â€“ fits the final model
  â€¢ Trained and tested on the dataset
  â€¢ Achieved an **RÂ² Score â‰ˆ 0.85**, showing strong model accuracy

---

### ğŸ“Š **Results & Insights**

* Polynomial regression captured complex relationships (e.g., between BMI and smoker status)
* The model explains ~85% of the variance in insurance charges
* **Smoker** is the most significant feature influencing medical costs
* Visualizations show predicted vs. actual charges closely aligned with the diagonal (perfect prediction line)

---

### ğŸ–¼ **Visualization Example**

```python
plt.figure(figsize=(6,6))
plt.scatter(Y_test, Y_pred_poly, alpha=0.6, color='teal')
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()],
         color='red', linestyle='--', linewidth=2, label='Perfect Prediction')
plt.xlabel("Actual Charges")
plt.ylabel("Predicted Charges")
plt.title("Actual vs Predicted Medical Charges (Polynomial Regression)")
plt.legend()
plt.show()
```

---

### ğŸ§¾ **Conclusion**

Polynomial Regression (degree=2) with feature scaling improved prediction accuracy from ~0.75 to **0.85 RÂ²**, confirming the importance of capturing **non-linear interactions** in real-world cost prediction.


